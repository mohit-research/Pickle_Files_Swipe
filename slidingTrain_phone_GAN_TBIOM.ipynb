{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import seaborn as sns\n",
        "from math import sqrt\n",
        "from scipy.stats import gaussian_kde\n",
        "from operator import itemgetter\n",
        "import shutil\n",
        "import math\n",
        "import numpy as np\n",
        "import statistics as stat\n",
        "import random\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from authWithGAN import *\n",
        "\n",
        "def parse_demographics():\n",
        "    df = pd.read_csv(\"./Demographics.csv\", usecols=['Gender'])\n",
        "\n",
        "    result = []\n",
        "    ctr = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if (row[\"Gender\"] == \"M\"):\n",
        "            result.append(1)\n",
        "        else:\n",
        "            result.append(0)\n",
        "    return result\n",
        "\n",
        "def HTER(y, pred):\n",
        "        '''\n",
        "        Params: (Expected Binary Labels)\n",
        "        y: Original Labels\n",
        "        pred: Predicted Labels\n",
        "\n",
        "        Returns:\n",
        "        --------------\n",
        "        FAR, FRR, HTER respectively\n",
        "        '''\n",
        "        far = frr = 0\n",
        "        for i in range(len(y)):\n",
        "                if y[i] == 0 and pred[i] == 1:\n",
        "                        far += 1\n",
        "                if y[i] == 1 and pred[i] == 0:\n",
        "                        frr += 1\n",
        "        far /= len(y)   \n",
        "        frr /= len(y)   \n",
        "        hter = (frr + far)/2\n",
        "        return far, frr, hter\n",
        "\n",
        "\n",
        "\n",
        "def pickling(fname, obj):\n",
        "        f = open(fname, \"wb\")\n",
        "        pickle.dump(obj, f)\n",
        "        f.close()\n",
        "\n",
        "def unpickling(fname):\n",
        "        f = open(fname, 'rb')\n",
        "        g = pickle.load(f) \n",
        "        f.close()\n",
        "        return g\n",
        "\n",
        "def create_sliding_window(X, Y, n):\n",
        "        final_X = []\n",
        "        final_Y = []\n",
        "        for i in range(len(X)- n):\n",
        "                temp = []\n",
        "                for j in range(i, i + n):\n",
        "                        temp += X[j]\n",
        "                final_X.append(temp)\n",
        "                final_Y.append(Y[i+n])\n",
        "        return final_X, final_Y\n",
        "\n",
        "def binarize(u, id):\n",
        "\n",
        "        ans = []\n",
        "        for i in u:\n",
        "                if int(i) == int(id):\n",
        "                        ans.append(1)\n",
        "                else:\n",
        "                        ans.append(0)\n",
        "        return ans\n",
        "\n",
        "\n",
        "def compare_classification(label_name, model, device, user):\n",
        "        ''' Function to process the data, apply oversampling techniques (SMOTE) and run the classification model specified using GridSearchCV\n",
        "        Input:  label_name: The task to be performed (Gender, Major/Minor, Typing Style)\n",
        "                feature_type: The feature set to be used (Desktop, Phone, Tablet, Combined)\n",
        "                top_n_features: Thu number of features to be selected using Mutual Info criterion\n",
        "                model: The ML model to train and evaluate\n",
        "        Output: accuracy scores, best hyperparameters of the gridsearch run'''\n",
        "\n",
        "        user = str(user)+\"_GAN_BBMAS\"\n",
        "        if model == \"SVM\":      \n",
        "                # Set the parameters by cross-validation\n",
        "                \n",
        "                pipeline = Pipeline(\n",
        "                [\n",
        "                        ('selector',SelectKBest(mutual_info_classif)),\n",
        "                        ('model',SVC())\n",
        "                ]\n",
        "                )\n",
        "                clf = GridSearchCV(\n",
        "                        estimator=pipeline, param_grid={'selector__k':[50, 100, 150, 200, 235] }, scoring='accuracy', return_train_score=True\n",
        "                )\n",
        "                #clf = SVC()\n",
        "                clf.fit(X_train, y_train)\n",
        "\n",
        "                pickling(model + '_' + str(user) + \".pkl\", clf)\n",
        "\n",
        "                y_true, y_pred = y_test, clf.predict(X_test)\n",
        "                far, frr, hter = HTER(y_true, y_pred)\n",
        "                return accuracy_score(y_true, y_pred), 1, 1, far, frr, hter\n",
        "\n",
        "        if model == \"RForest\":\n",
        "                tuned_parameters = {\n",
        "                        'selector__k':[50, 100, 150, 200, 235]\n",
        "                }\n",
        "                pipeline = Pipeline(\n",
        "                [\n",
        "                        ('selector',SelectKBest(mutual_info_classif)),\n",
        "                        ('model',RandomForestClassifier())\n",
        "                ]\n",
        "                )\n",
        "                clf = GridSearchCV(\n",
        "                        estimator=pipeline, param_grid=tuned_parameters, scoring='accuracy', return_train_score=True\n",
        "                )\n",
        "                #clf = RandomForestClassifier(n_jobs=10)\n",
        "                clf.fit(X_train, y_train)\n",
        "\n",
        "                pickling(model + '_' + str(user) + \".pkl\", clf)\n",
        "                y_true, y_pred = y_test, clf.predict(X_test)\n",
        "                far, frr, hter = HTER(y_true, y_pred)\n",
        "                return accuracy_score(y_true, y_pred), 1, 1, far, frr, hter\n",
        "\n",
        "        if model == \"XGBoost\":\n",
        "                tuned_parameters = {\n",
        "                'selector__k': [50, 100, 150, 200, 235]\n",
        "                }\n",
        "                pipeline = Pipeline(\n",
        "                [\n",
        "                        ('selector',SelectKBest(mutual_info_classif)),\n",
        "                        ('model',xgb.XGBClassifier())\n",
        "                ]\n",
        "                )\n",
        "                clf = GridSearchCV(\n",
        "                        estimator=pipeline, param_grid=tuned_parameters, scoring='accuracy', return_train_score=True\n",
        "                )\n",
        "\n",
        "                #clf = xgb.XGBClassifier()\n",
        "                clf.fit(X_train, y_train)\n",
        "\n",
        "                pickling(model + '_' + str(user) + \".pkl\", clf)\n",
        "                y_true, y_pred = y_test, clf.predict(X_test)\n",
        "                far, frr, hter = HTER(y_true, y_pred)\n",
        "                return accuracy_score(y_true, y_pred), 1, 1, far, frr, hter\n",
        "\n",
        "        if model == \"MLP\":\n",
        "                tuned_parameters = {\n",
        "                        'selector__k':[50, 100, 150, 200, 235]\n",
        "                }\n",
        "                pipeline = Pipeline(\n",
        "                [\n",
        "                        ('selector',SelectKBest(mutual_info_classif)),\n",
        "                        ('model', MLPClassifier())\n",
        "                ]\n",
        "                )\n",
        "                clf = GridSearchCV(\n",
        "                         estimator=pipeline, param_grid=tuned_parameters, scoring='accuracy', return_train_score=True\n",
        "                )\n",
        "                #clf = MLPClassifier()\n",
        "                clf.fit(X_train, y_train)\n",
        "                pickling(model + '_' + str(user) + \".pkl\", clf)\n",
        "                y_true, y_pred = y_test, clf.predict(X_test)\n",
        "                far, frr, hter = HTER(y_true, y_pred)\n",
        "                return accuracy_score(y_true, y_pred), 1, 1, far, frr, hter\n",
        "\n",
        "def get_data(legitimate, size = 2):\n",
        "  X = unpickling(\"Pickle_Files_Swipe/features_X.pkl\")\n",
        "  u = unpickling(\"Pickle_Files_Swipe/Ids_U.pkl\")\n",
        "\n",
        "  X, u = create_sliding_window(X, u, 5)\n",
        "\n",
        "  X = np.array(X)\n",
        "  u = np.array(u)\n",
        "\n",
        "  data = X[np.where(u==str(legitimate))]\n",
        "  labels = [1]*len(data)\n",
        "  for i in range(1, 117):\n",
        "    if i == legitimate:\n",
        "      continue\n",
        "    temp = X[np.where(u==str(i))]\n",
        "    r = np.random.choice(temp.shape[0], size = size, replace=False)\n",
        "    data = np.concatenate((data, temp[r, :]))\n",
        "    labels += [0]*len(r)\n",
        "  return data, np.array(labels)\n",
        "\n",
        "\n",
        "results = []\n",
        "gender_list = parse_demographics()\n",
        "final_acc_m = []\n",
        "final_far_m = []\n",
        "final_frr_m = []\n",
        "final_hter_m = []\n",
        "final_acc_f = []\n",
        "final_far_f = []\n",
        "final_frr_f = []\n",
        "final_hter_f = []\n",
        "\n",
        "file_ptr = open(\"Results_GAN_BBMAS.out\", \"w\")\n",
        "for val in range(1, 117):\n",
        "        X, y = get_data(val, 3)\n",
        "        file_ptr.write(str(val)+\"\\n\")\n",
        "\n",
        "        X_matrix, y_vector = ADASYN(random_state=0).fit_resample(X, y)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "                        X_matrix, y_vector, test_size=0.4, stratify = y_vector, random_state=0)\n",
        "\n",
        "        pickling(\"X_Legit_NonGAN.pkl\", X_train[[np.where(y_train==1)]])\n",
        "        pickling(\"X_Adver_NonGAN.pkl\", X_train[[np.where(y_train==0)]])\n",
        "\n",
        "        X1 = np.concatenate((generate_samples(X_train[np.where(y_train==1)], 250),X_train[np.where(y_train==1)]), axis=0)\n",
        "        X0 = np.concatenate((generate_samples(X_train[np.where(y_train==0)], 250),X_train[np.where(y_train==0)]), axis=0)\n",
        "\n",
        "        pickling(\"X_Legit_GAN.pkl\", X1)\n",
        "        pickling(\"X_Adver_GAN.pkl\", X0)\n",
        "\n",
        "        X1 = unpickling(\"X_Legit_GAN.pkl\")\n",
        "        X0 = unpickling(\"X_Adver_GAN.pkl\")\n",
        "\n",
        "        X_matrix, y_train = np.concatenate((X1, X0),axis=0), [1]*len(X1)+[0]*len(X0)\n",
        "        scaler = preprocessing.StandardScaler().fit(X_matrix)\n",
        "        X_train = scaler.transform(X_matrix)\n",
        "        transformer = Normalizer().fit(X_train)\n",
        "        X_train = transformer.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "        X_test = transformer.transform(X_test)\n",
        "       \n",
        "        pickling(\"scaler_GAN_Phone_selectK.pkl\", scaler)\n",
        "        pickling(\"transformer_GAN_Phone_selectK.pkl\", transformer)\n",
        "\n",
        "        res = []\n",
        "        # function to call the compare_classification function for the specified model, feature_type and task\n",
        "        def classification_results(problem, model, device, val):\n",
        "                ac, setup, vali, far, frr, hter = compare_classification(problem, model, device,val)\n",
        "                if (gender_list[val] == 1):\n",
        "                    final_acc_m.append(ac)\n",
        "                    final_far_m.append(far)\n",
        "                    final_frr_m.append(frr)\n",
        "                    final_hter_m.append(hter)\n",
        "                else:\n",
        "                    final_acc_f.append(ac)\n",
        "                    final_far_f.append(far)\n",
        "                    final_frr_f.append(frr)\n",
        "                    final_hter_f.append(hter)\n",
        "                res.append([ac, frr, far, hter])\n",
        "\n",
        "        device = [\"Phone\"]\n",
        "        class_problems = [\"Authentication\"]\n",
        "        models = [\"RForest\"]#[\"RForest\", \"XGBoost\", \"MLP\", \"SVM\"] #, \"DTree\", \"Logistic\"]#[\"RForest\", \"NB\", \"XGBoost\", \"MLP\", \"SVM\"]\n",
        "        # models = [\"SVM\"]\n",
        "\n",
        "        for model in models:\n",
        "                print(\"###########################################################################################\")\n",
        "                print(model)\n",
        "                file_ptr.write(\"Model is:\"+str(model)+\"\\n\")\n",
        "                for class_problem in class_problems:\n",
        "                        print(class_problem)\n",
        "                        for dev in device:\n",
        "                                print(dev)\n",
        "                                classification_results(class_problem, model, dev,val)\n",
        "                                print()\n",
        "                                print(\"-----------------------------------------------------------------------------------------\")\n",
        "        results.append(res)\n",
        "\n",
        "print(\"Accuracy Male:\",np.mean(final_acc_m))\n",
        "print(\"Accuracy Female:\",np.mean(final_acc_f))\n",
        "print(\"FAR Male:\",np.mean(final_far_m))\n",
        "print(\"FAR Female:\",np.mean(final_far_f))\n",
        "print(\"HTER Male:\",np.mean(final_hter_m))\n",
        "print(\"HTER Female:\",np.mean(final_hter_f))\n",
        "\n",
        "def avg_utility(r):\n",
        "        final = []\n",
        "        for m in range(len(r[0])):\n",
        "                tmp = []\n",
        "                for k in range(len(r[0][0])):\n",
        "                        ans = 0\n",
        "                        for i in range(len(r)):\n",
        "                                ans += r[i][m][k]\n",
        "                        ans /= len(r)\n",
        "                        tmp.append(ans)\n",
        "                final.append(tmp)\n",
        "        return final\n",
        "\n",
        "print (avg_utility(results))\n",
        "file_ptr.write(\"Average:\"+str(avg_utility(results))+\"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}